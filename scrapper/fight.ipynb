{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilling the web into GIS datasets\n",
    "\n",
    "- Amanda Vann\n",
    "\n",
    "\n",
    "Scrapping:  \n",
    ">The capabilities of distiling web information is endlessly useful.  For example a lot of information is avialble online which could be made more interactive and accessable if it was able to be used through maps.  One such group is collecting the databases of the name and location of cemetary plots. With the ability to easily geocode where the cemetaries in each city are on the map, and then add the map and geodata of the plot cites, they could have a map program that could dirrect users not only to the cemetary where a reletive is buried, but to a plot point on a cemetary map that could bring them within feet if not dirrectly to the exact grave site.\n",
    "\n",
    "Source URL: http://www.partybusseattle.com/covington_bars.html   \n",
    "Files: https://github.com/UW-GEOG458-Winter2016/avann/tree/gh-pages/distillingweb/files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting out:  \n",
    ">I had intitialy planed to run googlescrapper along with several other API scripts and tools and had spent five to six days trying to get one of them to work.  Unfortunetly I got none of them to work and had hit several walls before eventualy deciding on the 2/17/19 to stick with HTML for this project and continue to work at trying to see what I did wrong with the API scripts with the final. Due to working on the project in patches, it is difficult to include all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Applebee's\", \"Trapper's Sushi\", 'Red Robin', \"Nikki's Restaurant &amp; Lounge\", 'Mizu Japanese Steak House', 'Puerto Vallarta']\n",
      "['17040 SE 272nd St, \\nCovington, WA 98042', '16908 SE 269th Pl, \\nCovington, WA 98042', '27193 185th Avenue SE, \\nCovington, WA 98042', '27120 174th Pl SE, \\nCovington, WA 98042', '27149 185th Ave SE, \\nCovington, WA 98042', '16717 SE 272nd St, \\nCovington, WA 98042']\n",
      "['(253) 856-1900', '(253) 277-0926', 'Phone number (253) 630-5441', '(253) 236-5623', '(253) 638-1317', '(253) 631-1399']\n",
      "[\"Applebee's might be a chain restaurant but it's one that is so ideally suited to Party Bus Seattle groups traveling in Covington. They've got an awesome bar area here where you and your party bus group will enjoy chilling and watching sports on TV, while you sip delicious specialty cocktails and nosh on incredible appetizers. As far as the entrees go, we are madly in love with the garlic sirloin with redskin potatoes and stuffed mushroom caps. Absolutely delicious. They've got really good wings too if you're in the mood for bar fare!\", \"Trapper's Sushi is a delightful Japanese restaurant and sushi bar that will be such a great destination for your Party Bus Seattle groups in Covington. They've got such outstanding maki selections here, including our favorites, the spider roll and the Philly roll. We always judge a sushi restaurant by the quality of their salmon roe nigiri, and we're happy to say that theirs is off-the-charts delish! The sake selection is impressive and very tasty, and what better way to wash down a stellar meal of sushi and sashimi than that? Love it!\", \"Red Robin is another chain that we really like. Enough Party Bus Seattle groups in the Covington area have chosen this one as their dining destination that we had to perk up and take notice! They've got really tasty burgers that are juicy and perfectly cooked to order. The array of specialty burgers is always impressive and they're always offering new seasonal specialties to keep things fresh. If you're not a burger lover, they have fantastic entrees and salads too, and even mouth watering milkshakes! We recommend the mint brownie. Mmm!\", \"Nikki's Restaurant &amp; Lounge is a cozy diner and bar that is well known to our Party Bus Seattle partygoers in the Covington vicinity. They offer a full bar and even televisions so that you can keep an eye on the game while you nosh and chat with your friends. It's not fancy here, just simple and good, with nice happy hour prices that will really put a smile on your face. If you've got a sweet tooth, don't shy away from their homemade cinnamon rolls. If you're there for breakfast, they've got scrambles that will really please your tastebuds.\", \"Mizu Japanese Steak House is a sushi bar and seafood/steakhouse style restaurant that will entice your tastebuds to no end. If you love teppanyaki style cooking, you'll really enjoy the entertainment that comes along with that, and the quality of the food is undeniable. Their fried rice is some of the best that we have ever tasted. The space is large and they have lots of windows to let the light in. There is a full bar here, not just sake, so you can enjoy whatever drink your little heart is in the mood for. Free wi-fi and televisions as well! Very nice.\", \"Puerto Vallarta is a sensational Mexican restaurant that even offers an impressive buffet. The prices here are in the affordable range and the quality is super high. The chimichanga special is truly mouth watering and we cannot get enough of their famous tortilla soup. Their carne asada is another amazing choice that we'd recommend any day of the week! There is a full bar as well as televisions for watching sports, and though they close up at 11:30 most nights, they are open until 1:30 am on Fridays and Saturdays. A great weekend destination!\"]\n"
     ]
    }
   ],
   "source": [
    "# This script took the longest amount of time to get to work due to running \n",
    "# through a wide variaty of scripts and methods. \n",
    "# I have several notebooks of other scrap scripts I had unsuccessfuly \n",
    "# attempted before eventualy getting frustrated and 'going back to the basics' \n",
    "# so as to try to walk through the script so as to break them into lists that \n",
    "# perhaps could be read into CSV files. I focused on this script rather then \n",
    "# continue to fight other scripts/api libraries I had hoped to get working.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "import lxml\n",
    "import re\n",
    "\n",
    "page = urllib2.urlopen(\"http://www.partybusseattle.com/covington_bars.html\")\n",
    "soup = BeautifulSoup(page)\n",
    "food = soup.find_all(\"div\", \"five_veh columns\") #finding the table\n",
    "# Initialy ran with test print to make sure it worked and then went back and started to break the code down.\n",
    "    \n",
    "site = []\n",
    "location = []\n",
    "phone = []\n",
    "desc = []\n",
    "data = []\n",
    "i = 0\n",
    "\n",
    "for dinner in food:\n",
    "    for row in dinner:\n",
    "        row.renderContents()\n",
    "        i = i + 1  \n",
    "        if i == 1: # Added so as to try to get the information sorted into the right lists\n",
    "            text=row.renderContents().strip('\\n') \n",
    "            #  Eventualy added renderContents due to issues with stripping the HTML.\n",
    "            #  I had tried various ways of getting beutifulsoup to strip html, but then ran into issues \n",
    "            #  when it came to getting the content I was trying to put into tables.\n",
    "            site.append(text)\n",
    "        if i == 2:\n",
    "            text=row.renderContents().strip('\\n')\n",
    "            location.append(text)\n",
    "        if i == 3:\n",
    "            text=row.renderContents().strip('\\n')\n",
    "            phone.append(text)\n",
    "        if i == 4:\n",
    "            text=row.renderContents().strip('\\n')\n",
    "            desc.append(text)\n",
    "            i = 0\n",
    "        \n",
    "print site\n",
    "print location\n",
    "print phone\n",
    "print desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing Google API\n",
    "from googlemaps import GoogleMaps\n",
    "API_Key = \"AIzaSyC_KT0sakx22S31F-u0oekHEBW_bmucEcY\"\n",
    "gmaps = GoogleMaps(API_Key) \n",
    "address = '17040 SE 272nd St, WA'\n",
    "lat, lng = gmaps.address_to_latlng(address)\n",
    "print lat, lng\n",
    "\n",
    "# Recieved error; HTTPError: HTTP Error 403: Forbidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to stackoverflow, the Api v2 was closed down on sept 13, 2013.\n",
    "I attempted to apply the '_DIRECTIONS_QUERY_URL = 'http://maps.googleapis.com/maps/api/directions/output?' suggested edit.  \n",
    "The module gave an error when I re-ran it and the googlemaps.py still wont work for me. I needed to find another way to get the coords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['17040 SE 272nd St, \\nCovington, WA 98042', '16908 SE 269th Pl, \\nCovington, WA 98042', '27193 185th Avenue SE, \\nCovington, WA 98042', '27120 174th Pl SE, \\nCovington, WA 98042', '27149 185th Ave SE, \\nCovington, WA 98042', '16717 SE 272nd St, \\nCovington, WA 98042']\n"
     ]
    }
   ],
   "source": [
    "print location #doublechecking list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'lat': 47.3582473, u'lng': -122.1138343}\n",
      "{u'lat': 47.360591, u'lng': -122.115313}\n",
      "{u'lat': 47.3583314, u'lng': -122.1001497}\n",
      "{u'lat': 47.3584977, u'lng': -122.1087012}\n",
      "{u'lat': 47.3582956, u'lng': -122.0976919}\n",
      "{u'lat': 47.3574042, u'lng': -122.1196492}\n",
      "[{u'lat': 47.3582473, u'lng': -122.1138343}, {u'lat': 47.360591, u'lng': -122.115313}, {u'lat': 47.3583314, u'lng': -122.1001497}, {u'lat': 47.3584977, u'lng': -122.1087012}, {u'lat': 47.3582956, u'lng': -122.0976919}, {u'lat': 47.3574042, u'lng': -122.1196492}]\n"
     ]
    }
   ],
   "source": [
    "# After trial and error with trying to get geocoders to work, \n",
    "# I was finaly able to find a code that would help on stack exchange.\n",
    "import requests\n",
    "\n",
    "coords = [] #To store the code\n",
    "\n",
    "for loc in location:\n",
    "    response = requests.get('https://maps.googleapis.com/maps/api/geocode/json?address=' + loc)\n",
    "    resp_json_payload = response.json()\n",
    "    coords.append(resp_json_payload['results'][0]['geometry']['location'])\n",
    "    print(resp_json_payload['results'][0]['geometry']['location'])\n",
    "print coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">%run \"c:\\users\\whtcrow\\appdata\\local\\temp\\tmpep4pgw.py\"  \n",
    ">  File \"c:\\users\\whtcrow\\appdata\\local\\temp\\tmpep4pgw.py\", line 1  \n",
    ">    pip install C:/Users/Whtcrow/Mapping/workspace/geopy-1.11.0-py2.py3-none-any.whl  \n",
    ">              ^   \n",
    ">SyntaxError: invalid syntax   \n",
    "    \n",
    "Pip would not install Geopy and it was not on the module options in canopy package manager.  \n",
    "I eventualy was able to find out part of the cause through looking up the error code. Pip needed to be run from command prompt verses the python window. After running pip in the command prompt window (and it claiming that it was successful) I was still unable to get Geopy to be a recognizable module and to work.  I tried downloading the masterfile of Geopy from Github and running it through Canopy only to recieve the following error;\n",
    "\n",
    "> error: no commands supplied\n",
    "\n",
    "Simular issues were found with Geocoder, Geonames and other modules that I tried to install which were not available through Package Manager. Geonames and other modules offered different errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((u'lat', 47.3582473), (u'lat', 47.360591), (u'lat', 47.3583314), (u'lat', 47.3584977), (u'lat', 47.3582956), (u'lat', 47.3574042))\n",
      "((u'lng', -122.1138343), (u'lng', -122.115313), (u'lng', -122.1001497), (u'lng', -122.1087012), (u'lng', -122.0976919), (u'lng', -122.1196492))\n"
     ]
    }
   ],
   "source": [
    "# prepping coords\n",
    "fixed_list = [loc.items() for loc in coords]\n",
    "lat,lng = zip(*fixed_list)\n",
    "print lat\n",
    "print lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'lat', 47.3582473], [u'lat', 47.360591], [u'lat', 47.3583314], [u'lat', 47.3584977], [u'lat', 47.3582956], [u'lat', 47.3574042]]\n",
      "[[u'lng', -122.1138343], [u'lng', -122.115313], [u'lng', -122.1001497], [u'lng', -122.1087012], [u'lng', -122.0976919], [u'lng', -122.1196492]]\n"
     ]
    }
   ],
   "source": [
    "# turning the tuples back into lists\n",
    "lat = [list(l) for l in lat]\n",
    "lng = [list(l) for l in lng]\n",
    "print(lat)\n",
    "print(lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47.3582473], [47.360591], [47.3583314], [47.3584977], [47.3582956], [47.3574042]]\n",
      "[[-122.1138343], [-122.115313], [-122.1001497], [-122.1087012], [-122.0976919], [-122.1196492]]\n"
     ]
    }
   ],
   "source": [
    "# I used this to remove the u'lat' and u'lng' from the lists.\n",
    "for l in lat:\n",
    "    del l[0]\n",
    "print lat\n",
    "\n",
    "for l in lng:\n",
    "    del l[0]\n",
    "print lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.3582473, 47.360591, 47.3583314, 47.3584977, 47.3582956, 47.3574042]\n",
      "[-122.1138343, -122.115313, -122.1001497, -122.1087012, -122.0976919, -122.1196492]\n"
     ]
    }
   ],
   "source": [
    "#getting rid of the lists of lists glitch\n",
    "lat2 = []\n",
    "lng2 = []\n",
    "\n",
    "for item in lat:\n",
    "    for i in item:\n",
    "        lat2.append(i)\n",
    "for item in lng:\n",
    "    for i in item:\n",
    "        lng2.append(i)\n",
    "print lat2\n",
    "print lng2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"Applebee's\", '17040 SE 272nd St, \\nCovington, WA 98042', '(253) 856-1900', \"Applebee's might be a chain restaurant but it's one that is so ideally suited to Party Bus Seattle groups traveling in Covington. They've got an awesome bar area here where you and your party bus group will enjoy chilling and watching sports on TV, while you sip delicious specialty cocktails and nosh on incredible appetizers. As far as the entrees go, we are madly in love with the garlic sirloin with redskin potatoes and stuffed mushroom caps. Absolutely delicious. They've got really good wings too if you're in the mood for bar fare!\", 47.3582473, -122.1138343), (\"Trapper's Sushi\", '16908 SE 269th Pl, \\nCovington, WA 98042', '(253) 277-0926', \"Trapper's Sushi is a delightful Japanese restaurant and sushi bar that will be such a great destination for your Party Bus Seattle groups in Covington. They've got such outstanding maki selections here, including our favorites, the spider roll and the Philly roll. We always judge a sushi restaurant by the quality of their salmon roe nigiri, and we're happy to say that theirs is off-the-charts delish! The sake selection is impressive and very tasty, and what better way to wash down a stellar meal of sushi and sashimi than that? Love it!\", 47.360591, -122.115313), ('Red Robin', '27193 185th Avenue SE, \\nCovington, WA 98042', 'Phone number (253) 630-5441', \"Red Robin is another chain that we really like. Enough Party Bus Seattle groups in the Covington area have chosen this one as their dining destination that we had to perk up and take notice! They've got really tasty burgers that are juicy and perfectly cooked to order. The array of specialty burgers is always impressive and they're always offering new seasonal specialties to keep things fresh. If you're not a burger lover, they have fantastic entrees and salads too, and even mouth watering milkshakes! We recommend the mint brownie. Mmm!\", 47.3583314, -122.1001497), (\"Nikki's Restaurant &amp; Lounge\", '27120 174th Pl SE, \\nCovington, WA 98042', '(253) 236-5623', \"Nikki's Restaurant &amp; Lounge is a cozy diner and bar that is well known to our Party Bus Seattle partygoers in the Covington vicinity. They offer a full bar and even televisions so that you can keep an eye on the game while you nosh and chat with your friends. It's not fancy here, just simple and good, with nice happy hour prices that will really put a smile on your face. If you've got a sweet tooth, don't shy away from their homemade cinnamon rolls. If you're there for breakfast, they've got scrambles that will really please your tastebuds.\", 47.3584977, -122.1087012), ('Mizu Japanese Steak House', '27149 185th Ave SE, \\nCovington, WA 98042', '(253) 638-1317', \"Mizu Japanese Steak House is a sushi bar and seafood/steakhouse style restaurant that will entice your tastebuds to no end. If you love teppanyaki style cooking, you'll really enjoy the entertainment that comes along with that, and the quality of the food is undeniable. Their fried rice is some of the best that we have ever tasted. The space is large and they have lots of windows to let the light in. There is a full bar here, not just sake, so you can enjoy whatever drink your little heart is in the mood for. Free wi-fi and televisions as well! Very nice.\", 47.3582956, -122.0976919), ('Puerto Vallarta', '16717 SE 272nd St, \\nCovington, WA 98042', '(253) 631-1399', \"Puerto Vallarta is a sensational Mexican restaurant that even offers an impressive buffet. The prices here are in the affordable range and the quality is super high. The chimichanga special is truly mouth watering and we cannot get enough of their famous tortilla soup. Their carne asada is another amazing choice that we'd recommend any day of the week! There is a full bar as well as televisions for watching sports, and though they close up at 11:30 most nights, they are open until 1:30 am on Fridays and Saturdays. A great weekend destination!\", 47.3574042, -122.1196492)]\n"
     ]
    }
   ],
   "source": [
    "# zipping it all up for ease of csv tranformation\n",
    "alldata = zip(site,location,phone,desc,lat2,lng2)\n",
    "print alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fieldnames set.\n",
      "CSV writen.\n",
      "CSV writen.\n",
      "CSV writen.\n",
      "CSV writen.\n",
      "CSV writen.\n",
      "CSV writen.\n"
     ]
    }
   ],
   "source": [
    "#bringing it all together\n",
    "import csv\n",
    "\n",
    "foodcsv = open(\"C:/Users/Whtcrow/Mapping/workspace/food3.csv\", 'wb')\n",
    "with open('food3.csv', 'w') as csvfile:\n",
    "    fieldnames = [\"site\", \"location\", \"phone\", \"desc\", \"lat\", \"lng\"]\n",
    "    print \"Fieldnames set.\"\n",
    "\n",
    "for i in alldata:\n",
    "    csv.writer(foodcsv).writerow(i)\n",
    "    print \"CSV writen.\"\n",
    "\n",
    "foodcsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'food.csv', mode 'w' at 0x12A18440>\n",
      "['site', 'location', 'phone', 'desc', 'lat', 'lng']\n"
     ]
    }
   ],
   "source": [
    "foodcsv = open(\"C:/Users/Whtcrow/Mapping/workspace/food.csv\", 'wb')\n",
    "with open('food.csv', 'w') as csvfile:\n",
    "    print csvfile\n",
    "    print fieldnames\n",
    "foodcsv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially attempted to import a JSON and make one straight from the CSV file but then hit issues when it came to making a shapefile from the json file. I had also attempted to use JSONToFeatures_conversion, but that did not seem to work.  Therefore I went back and tried to make a script that would make a shapefile from the CSV file instead.  \n",
    "\n",
    "Using Arcmap as a guide, I tried to make a layer from the XY information in the CSV file first. As that did not work, I tried a few other methods until using CreateFeatureClass_Management, which worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#because arcpy\n",
    "import sys\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\bin')\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\arcpy')\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\ArcToolbox\\\\Scripts')\n",
    "\n",
    "import arcpy\n",
    "import os\n",
    "arcpy.env.workspace = r\"C:\\Users\\Whtcrow\\Mapping\\workspace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Whtcrow\\\\Mapping\\\\workspace\\\\diningareas2.shp'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcpy import env\n",
    "\n",
    "# Setup\n",
    "ws = r\"C:\\Users\\Whtcrow\\Mapping\\workspace\"\n",
    "out_name = \"diningareas2.shp\"\n",
    "geometry_type = \"POINT\"\n",
    "has_m = \"DISABLED\"\n",
    "has_z = \"DISABLED\"\n",
    "\n",
    "# Setting up a SpatialReference object so it works in ArcMap\n",
    "# spRef = r\"C:\\Users\\Whtcrow\\OneDrive\\Documents\\UW\\GEOG 360 GIS\\mgisdata\\World\\latlong.prj\"\n",
    "# Later on in the script I was fighting with XYmanager and decided to set up an arcmap projection\n",
    "SpRef2 = \"C:/Users/Whtcrow/AppData/Roaming/ESRI/Desktop10.3/ArcMap/Coordinate Systems/NAD 1983.prj\"\n",
    "# Remade shapefile based off of this projection.\n",
    "\n",
    "# Createing the shapefile\n",
    "arcpy.CreateFeatureclass_management(ws, out_name, geometry_type, \"\", has_m, has_z, SpRef2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<csv.DictReader instance at 0x0E7015A8>\n",
      "PING!\n"
     ]
    }
   ],
   "source": [
    "# Now that I have my shapefile built, I need to get the data into it.\n",
    "\n",
    "import csv\n",
    "cursor = arcpy.InsertCursor(\"diningareas.shp\")\n",
    "\n",
    "with open('food.csv', 'rb') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    print reader\n",
    "    for row in reader:\n",
    "        print row # This is where it started to stop reading and I am not sure why.\n",
    "        feature = cursor.newRow()\n",
    "        print feature\n",
    "        coords = arcpy.CreateObject(\"Point\")\n",
    "        print coords\n",
    "        coords.X = row['lat']\n",
    "        coords.Y = row['lng']\n",
    "        print coords.x\n",
    "        print coords.y\n",
    "        feature.shape = coords\n",
    "        cursor.insertRow(feature)\n",
    "\n",
    "print \"PING!\" \n",
    "del cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The ping lied. Diningares.shp remained empty. I'm not sure what is wrong with the script and why it is not working.   \n",
    "> The loop script seems fine and I don't think a cursor would work here.\n",
    "\n",
    "After some researching, I stumbled upon the 'shapefile' module. Shapefile seems to have a nice code but like geopy and geocoder, it is not in Canopy's Package Manager and I can't seem to install it either through pip or manualy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Object: Error in executing tool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-ff2797462df3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeXYEventLayer_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mycoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpRef2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetMessages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeatureClassToFeatureClass_conversion\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0moutLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoodshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\ArcGIS\\Desktop10.3\\arcpy\\arcpy\\management.py\u001b[0m in \u001b[0;36mMakeXYEventLayer\u001b[1;34m(table, in_x_field, in_y_field, out_layer, spatial_reference, in_z_field)\u001b[0m\n\u001b[0;32m   7120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7121\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7122\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7124\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mgptooldoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SaveToLayerFile_management'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Object: Error in executing tool"
     ]
    }
   ],
   "source": [
    "# I had tried the following differnet ways but it did not seem to want to copy the information in the csv.\n",
    "workspace = \"C:/Users/Whtcrow/Mapping/workspace\"\n",
    "foodshape = \"dining2.shp\"\n",
    "foodcsv = open(\"C:/Users/Whtcrow/Mapping/workspace/food.csv\", 'wb')\n",
    "xcoords = lng2\n",
    "ycoords = lat2\n",
    "outLayer = \"food_layer\"\n",
    "\n",
    "# Spatial Reference\n",
    "SpRef = arcpy.SpatialReference(4269) # Trying to use one of ArcMap's spatials.\n",
    "            # 4269 is GCS_North_American_1983 Found in: \n",
    "            # http://resources.arcgis.com/en/help/main/10.1/018z/pdf/geographic_coordinate_systems.pdf\n",
    "# As SpRef did not seem to work, \n",
    "#I favorited the coordinate system and then attemtped to pull it from the folder\n",
    "SpRef2 = \"C:/Users/Whtcrow/AppData/Roaming/ESRI/Desktop10.3/ArcMap/Coordinate Systems/NAD 1983.prj\"\n",
    "\n",
    "\n",
    "with open('food.csv', 'w') as csvfile:\n",
    "    arcpy.MakeXYEventLayer_management(csvfile, xcoords, ycoords, outLayer, SpRef2, \"\")\n",
    "    print arcpy.GetMessages() \n",
    "    arcpy.FeatureClassToFeatureClass_conversion( outLayer, workspace, foodshape)\n",
    "    print arcpy.GetMessages() \n",
    "\n",
    "foodcsv.close()\n",
    "print arcpy.GetMessages() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/21/16: Still working on CSV/SHP conversions.\n",
    "\n",
    "> At least 5-6 hours had been spent on the overall coding per day, and all day on 19th and 20th. I had gone to the CS building to find python help, but there is none without paying tutors and I am broke. I had also gone to the CSSC room friday (I should have gone when I first started to have trouble), but the aid that knew python would not be in until monday.  I had sought help from freinds and family. My brother was able to help with building the lists for the CSV, as I had done my looping wrong and had too many counts in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I had issues getting MakeXYEventLayer to work, I tried converting CSV to a database file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named dbf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-799f98629d7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdbf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfoodcsvloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/Whtcrow/Mapping/workspace/food.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfood_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfoodcsvloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_disk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mfood_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named dbf"
     ]
    }
   ],
   "source": [
    "import dbf \n",
    "foodcsvloc = \"C:/Users/Whtcrow/Mapping/workspace/food.csv\"\n",
    "food_table = dbf.from_csv(csvfile=foodcsvloc, to_disk=True)\n",
    "print food_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could not find dbf in the Canopy Package Manager.\n",
    "##### Remembering that I can't manualy install moduels... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-100-0300ef1a742c>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-100-0300ef1a742c>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    arcpy.MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, SpRef2, \"\")\u001b[0m\n\u001b[1;37m                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "try: # doing the setup\n",
    "    in_Table = \"food3.csv\"\n",
    "    x_coords = \"Field6\"\n",
    "    y_coords = \"Field5\"\n",
    "    out_Layer = \"food_layer\"\n",
    "    saved_Layer = \"food.lyr\"\n",
    " \n",
    "    # Spatial reference\n",
    "    SpRef2 = \"C:/Users/Whtcrow/AppData/Roaming/ESRI/Desktop10.3/ArcMap/Coordinate Systems/NAD 1983.prj\"\n",
    " \n",
    "    # Again with the XY Event layer\n",
    "    arcpy.MakeXYEventLayer_management(in_Table, x_coords, y_coords, out_Layer, SpRef2, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 000728: Field lat does not exist within table\nERROR 000728: Field lng does not exist within table\nFailed to execute (MakeXYEventLayer).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-d0c61a9c90b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtemp_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# == \"input\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeXYEventLayer_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lat\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lng\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpRef2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# I have tried lat/long, field5/field6 both with and without caps and I can't get it to work.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFeatureClassToShapefile_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshp_output_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\ArcGIS\\Desktop10.3\\arcpy\\arcpy\\management.py\u001b[0m in \u001b[0;36mMakeXYEventLayer\u001b[1;34m(table, in_x_field, in_y_field, out_layer, spatial_reference, in_z_field)\u001b[0m\n\u001b[0;32m   7120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7121\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7122\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7124\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mgptooldoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SaveToLayerFile_management'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 000728: Field lat does not exist within table\nERROR 000728: Field lng does not exist within table\nFailed to execute (MakeXYEventLayer).\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "\n",
    "csv_input = \"C:/Users/Whtcrow/Mapping/workspace/food3.csv\"\n",
    "shp_output_dir = os.path.dirname(csv_input)\n",
    "temp_layer = os.path.splitext(os.path.basename(csv_input))[0] # == \"input\"\n",
    "\n",
    "arcpy.MakeXYEventLayer_management(csv_input, \"lat\", \"lng\", temp_layer, SpRef2)\n",
    "    # I have tried lat/long, field5/field6 both with and without caps and I can't get it to work.\n",
    "arcpy.FeatureClassToShapefile_conversion(temp_layer, shp_output_dir)\n",
    "arcpy.Delete_management(temp_layer) # clean up layer, for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'food3.csv', mode 'w' at 0x129E38B8>\n",
      "['site', 'location', 'phone', 'desc', 'lat', 'lng']\n"
     ]
    }
   ],
   "source": [
    "# The field lat and lng do exist within the table.\n",
    "foodcsv = open(\"C:/Users/Whtcrow/Mapping/workspace/food3.csv\", 'wb')\n",
    "with open('food3.csv', 'w') as csvfile:\n",
    "    print csvfile\n",
    "    print fieldnames\n",
    "foodcsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'food3.csv', mode 'rb' at 0x12A18498>\n",
      "<_csv.reader object at 0x12D91B70>\n"
     ]
    }
   ],
   "source": [
    "# The next three scripts are my just trying to get python to print the CSV contents...\n",
    "import csv\n",
    "with open('food3.csv', 'rb') as csvfile:\n",
    "    print csvfile\n",
    "    foodreader = csv.reader(csvfile)\n",
    "    print foodreader\n",
    "    for row in foodreader:\n",
    "        print ', '.join(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(open('food3.csv').read())  # Print will not give any results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-10331dd305df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'food3.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\Documents\\UW\\PYTHON\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\Documents\\UW\\PYTHON\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\Documents\\UW\\PYTHON\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\Documents\\UW\\PYTHON\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\Documents\\UW\\PYTHON\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:5030)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# Trying Pandas to see if it will read the file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('food3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                ... It was worth a shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuck.\n",
    "\n",
    "I cant get the CSV to write into shapefile.  \n",
    "I cant get the CSV to write into a database.    \n",
    "I cant get the python script to even read the content of the CSVs, despite that I can open them in Arcmap.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">... hour 5 of day 11 working on python scrapper.   \n",
    ">I notice that most of the class has used css, but I do not know anything about css and don't want to start over.  \n",
    ">This code is going to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Experimenting with lists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Applebee's\", \"Trapper's Sushi\", 'Red Robin', \"Nikki's Restaurant &amp; Lounge\", 'Mizu Japanese Steak House', 'Puerto Vallarta']\n",
      "[47.3582473, 47.360591, 47.3583314, 47.3584977, 47.3582956, 47.3574042]\n",
      "[-122.1138343, -122.115313, -122.1001497, -122.1087012, -122.0976919, -122.1196492]\n",
      "['(253) 856-1900', '(253) 277-0926', 'Phone number (253) 630-5441', '(253) 236-5623', '(253) 638-1317', '(253) 631-1399']\n"
     ]
    }
   ],
   "source": [
    "# I decided to stop fighting the CSV and go back to making a shapefile from text information.\n",
    "# Checking lists:\n",
    "print site\n",
    "print lat2\n",
    "print lng2\n",
    "print phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried a variety of scripts to get lists to read into shapefiles but I could not seem to get it to work.   \n",
    "For the sake of trying to keep the python notebook clean, I have left them out.    \n",
    "\n",
    "I went back to turning the CSV to a JSON file so as to try to make a shapefile from the JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "csvfile = open('food3.csv', 'r')\n",
    "jsonfile = open('foodjson.json', 'w')\n",
    "\n",
    "fieldnames = ('site', 'location', 'phone', 'desc', 'lat', 'lng')\n",
    "reader = csv.DictReader( csvfile, fieldnames)\n",
    "for row in reader:\n",
    "    json.dump(row, jsonfile)\n",
    "    jsonfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'C:/Users/Whtcrow/Mapping/workspace/foodjson.json', mode 'wb' at 0x129F04F0>\n",
      "('site', 'location', 'phone', 'desc', 'lat', 'lng')\n"
     ]
    }
   ],
   "source": [
    "foodjson = open(\"C:/Users/Whtcrow/Mapping/workspace/foodjson.json\", 'wb')\n",
    "with open('foodjson.json', 'w') as csvfile:\n",
    "    print foodjson\n",
    "    print fieldnames\n",
    "foodjson.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now to make the shapefile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "ERROR 001558: Error parsing json file 'foodjson.json'. \nFailed to execute (JSONToFeatures).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-06f1736a36a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJSONToFeatures_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"foodjson.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"foodgdb.shp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files (x86)\\ArcGIS\\Desktop10.3\\arcpy\\arcpy\\conversion.py\u001b[0m in \u001b[0;36mJSONToFeatures\u001b[1;34m(in_json_file, out_features)\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecuteError\u001b[0m: ERROR 001558: Error parsing json file 'foodjson.json'. \nFailed to execute (JSONToFeatures).\n"
     ]
    }
   ],
   "source": [
    "# Trying again with JsontoFeatures...\n",
    "import arcpy\n",
    "import os\n",
    "arcpy.JSONToFeatures_conversion(\"foodjson.json\", os.path.join(\"foodgdb.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same error as before.  Trying again using other variations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-a0de53df87e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfoodjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Whtcrow/Mapping/workspace/foodjson.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Whtcrow/Mapping/workspace/foodjson.json'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[0mparse_constant\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_constant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_pairs_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_pairs_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m         **kw)\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Whtcrow\\AppData\\Local\\Enthought\\Canopy32\\App\\appdata\\canopy-1.6.2.3262.win-x86\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No JSON object could be decoded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "foodjson = open(\"C:/Users/Whtcrow/Mapping/workspace/foodjson.json\", 'wb')\n",
    "with open('C:/Users/Whtcrow/Mapping/workspace/foodjson.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for feature in data['features']:\n",
    "    print feature['geometry']['type']\n",
    "    print feature['geometry']['coordinates']\n",
    "foodjson.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<open file 'C:/Users/Whtcrow/Mapping/workspace/foodjson.json', mode 'wb' at 0x12CC1910>\n",
      "('site', 'location', 'phone', 'desc', 'lat', 'lng')\n"
     ]
    }
   ],
   "source": [
    "#  Re-affirming that the file is definitely there and has content\n",
    "foodjson = open(\"C:/Users/Whtcrow/Mapping/workspace/foodjson.json\", 'wb')\n",
    "with open('foodjson.json', 'w') as csvfile:\n",
    "    print foodjson\n",
    "    print fieldnames\n",
    "foodjson.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
