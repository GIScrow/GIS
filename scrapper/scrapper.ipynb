{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now to try something completely different.\n",
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "page = requests.get('http://www.saffrongrillseattle.com/saffrongrill/lunchmenu.html')\n",
    "tree = html.fromstring(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A list of lunch titles:\n",
    "title = tree.xpath('//span[@class=\"title_lunchmenu\"]/text()')\n",
    "print title\n",
    "\n",
    "#A list of the lunch texts:\n",
    "text = tree.xpath('//span[@class=\"text_luchmenu\"]/text()')\n",
    "print text\n",
    "\n",
    "#A list of lunch prices:\n",
    "price= tree.xpath('//span[@class=\"price_lunchmenu\"]/text()')\n",
    "print price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#A list of lunch prices:\n",
    "#A list of lunch titles:\n",
    "title2 = tree.xpath('//div[@class=\"title_lunchmenu\"]/text()')\n",
    "print title2\n",
    "\n",
    "#A list of the lunch texts:\n",
    "text2 = tree.xpath('//div[@class=\"text_luchmenu\"]/text()')\n",
    "print text2\n",
    "\n",
    "#prices\n",
    "price2= tree.xpath('//div[@class=\"price_lunchmenu\"]/text()')\n",
    "print price3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Lunchmenu: ',title\n",
    "print 'Content: ', text\n",
    "print 'Prices: ', prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price2= tree.xpath('//div[@valign=\"bottom\"]/text()')\n",
    "print price2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and back to beautifulsoup\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "r = urllib.urlopen('http://www.saffrongrillseattle.com/saffrongrill/lunchmenu.html').read()\n",
    "soup = BeautifulSoup(r)\n",
    "print type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "food = soup.find_all(\"div\", class_=\"title_lunchmenu\")\n",
    "print type(food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price = soup.find_all(valign=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in price:\n",
    "    price[p.a.get_text()] = {}\n",
    "print price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lobbying = {}\n",
    "for element in price:\n",
    "    lobbying[element.a.get_text()] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = lxml.html.fromstring(response.content)\n",
    "for item in tree.xpath('valign=/div/img/following-sibling::text()'):\n",
    "    print item.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "http://web.stanford.edu/~zlotnick/TextAsData/Web_Scraping_with_Beautiful_Soup.html\n",
    "https://adesquared.wordpress.com/2013/06/16/using-python-beautifulsoup-to-scrape-a-wikipedia-table/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
